{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation 1\n",
    "in this notebook we show how we perform some manipulation on the full dataset in order to prepare it to feed the LSTM\n",
    "\n",
    "the code for performing the data preparation on the test dataset is exactly the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('train_after_preprocess.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at this point we encoded the events in a different way, we add a column for each possible event and we add a 1 in the column corresponding with the event or events (there may be simultaneous events) occuring in that quarter hour, 0 otherwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute a list of all the possible events occuring\n",
    "list_of_events = dataset[['EVENT_TYPE1', 'EVENT_TYPE2', 'EVENT_TYPE3', 'EVENT_TYPE4']].stack().unique()\n",
    "# list_of_events = ['NO_EVENT', 'Veicolo_in_avaria', 'Ostacolo_in_carreggiata', 'Regimazione_delle_acque','Manutenzione_opere_in_verde', 'Meteo', 'Gestione_viabilita', 'extended_accident', 'Segnaletica_orizzontale','Allarme', 'Segnaletica_verticale', 'Pavimentazione', 'Barriere', 'Opera_arte', 'Calamita_naturale']\n",
    "\n",
    "print(list_of_events)\n",
    "print(len(list_of_events))\n",
    "\n",
    "# delete no event since we don't want a column with no event or nan values\n",
    "list_of_events.remove('NO_EVENT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_columns_to_dataframe(dataframe, list_of_events):\n",
    "    for event in list_of_events:\n",
    "        dataframe[event] = np.int8(0)\n",
    "    return dataframe\n",
    "\n",
    "# add columns to the dataset, one for each event (for now all with zeros)\n",
    "dataset = add_columns_to_dataframe(dataset, list_of_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ones(dataframe):\n",
    "    for index, row in dataframe.iterrows():\n",
    "        print(index)\n",
    "        for i in range(1, 5):\n",
    "            if (row['EVENT_TYPE' + str(i)] != 'NO_EVENT'):\n",
    "                event_type = row['EVENT_TYPE' + str(i)]\n",
    "                dataframe.at[index, event_type] = np.int8(1)\n",
    "    return dataframe\n",
    "\n",
    "dataset = add_ones(dataset)\n",
    "\n",
    "print(dataset.info())\n",
    "\n",
    "dataset.to_csv('train_final.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
